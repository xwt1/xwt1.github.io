# ParlayANN: Scalable and Deterministic Parallel Graph-Based Approximate Nearest Neighbor Search Algorithms

主要贡献：基于图的多线程工作，用于优化已有的索引。

## 1. introduction

- 首先提出在核数不断增加，数据量不断增大的情况下，原始图索引的加速效果可能没有提升非常明显。
- 于是ParlayANN想办法构造特定的多线程算法，以解决这个问题。
- 总的来说，文章有几个贡献：
    - **确定性和并行实现**：引入了ParlayANN，一个确定性和并行的基于图的近似最近邻搜索（ANNS）算法库。该库包括四种最新的基于图的ANNS算法的并行实现，这些算法能够扩展到亿级规模的数据集，并在多样化的数据集上确保高扩展性。
    - **算法和实验创新**：开发了用于并行化基于图的ANNS算法的新算法思路，并进行了全面的实验研究。实验结果验证了新技术的有效性，并对不同ANNS算法在大规模数据集上的表现进行了全面比较，揭示了各种有趣的发现。
    - **可扩展性和性能**：展示了所提出算法的高可扩展性，这些算法能够有效利用大量处理器，避免了锁和顺序处理带来的瓶颈。实验结果突出了ParlayANN实现相比现有方法在吞吐量和召回率平衡方面的优越性能。
    - **通用并行化技术**：介绍了如前缀倍增和批量更新等通用技术，用于并行构建ANNS图，这些技术适用于多种算法。这些技术帮助消除了锁，确保了确定性输出，从而提高了性能和正确性。
    - **深入的基准测试**：对新算法进行了详细的基准测试，并与现有的非图方法进行了比较，展示了在亿级数据集上可扩展性和性能方面的优势。结果表明，ParlayANN实现的算法在各种召回率水平上都实现了最佳的召回率和每秒查询数（QPS）之间的权衡。

## 2. Preliminaries

- Parallel Model（并行化模型）：
    
    使用了fork-join model，这种模型可以共享一片内存，一个进程可以fork两个孩子线程实现并行化。当孩子进程全部结束后，父进程继续。对于一个遍历for循环中$n$个items，可以递归地fork $log(n)$层来完成。在模型中的计算任务可以使用随机工作窃取调度器（randomized work-stealing scheduler）可以有效地分配和执行任务。工作窃取是一种任务调度策略，其中空闲的处理器（或线程）会动态地从其他忙碌的处理器的任务队列中窃取任务来执行。
    
    文章定义一个并行计算算法是**确定**的，只有它能在多次测试中对于同一个输入给出相同的结果。如果一个算法中本身就有随机化算法，就将其随机化输入（种子）当成输入的一部分。
    
- Parallel Semisort（并行化半排序）：
    
    文章中很多地方用了并行化半排序。半排序的定义是：**首先**确保所有键值相同的元素在输出序列中彼此相邻，但这些元素之间不需要进一步排序（也就是不需要完全排序）。
    

## 3. 图索引的普遍技术

- 首先半篇内容都是普通的图搜索，别水了别水了，这个都快讲烂了。然后是增量算法。

### 3.1 增量算法

大致介绍了目前的增量添加算法。

- 说明了目前增量算法的挑战：为了实现并行化增量ANN算法，许多现存的办法都是单线程添所有点（这个地方是不是有问题？至少HNSW早就实现多线程添点了，DISKANN也是）。
- 介绍了ANNS的新技术：Prefix Doubling，首先分析原先图索引为什么要加锁，原因是因为每一个新添加的点，都需要在添加时知道已有的图索引的结构，从而知道与哪些已有的点建立联系。用锁可以很好地序列化添加点的顺序，减少冲突并且接近于序列化添加算法，但是会有性能问题。（感觉这个地方逻辑性不是很强？即使不严格按照序列的顺序，图索引的性能也不一定会下降）。
    
    为了解决性能问题，Prefix Doubling添加点的时候，会按照批次添加点，这些批次的大小呈指数级增长，直到达到参数𝜃定义的上限。每一个点在添加的时候会基于在某一个批次结尾的快照，因此，每个点添加的时候不会与其余点起冲突。
    
    具体一点，一开始，批次较小，与顺序插入过程相似，有助于创建更准确的索引。随着索引的增长，批次大小按指数级增加，允许高并行性和高效的点插入。此方法在并行性、进度和准确性之间取得了平衡，使图的构建过程高效且可扩展，而不会出现使用锁时的争用问题。
    
    序列化算法在添加第$i$个点的时候，会基于前$i-1$个点构建。与序列化添加算法比起来，Prefix Doubling会基于前$O(i)$个点构建，大致是基于$\frac{i}{2}$个点构建，而且这个构建算法是确定性构建算法，保证了较高的并行性。
    
    当添加许多点进入到索引的时候，如果有一些点$P$要与索引中的某个点$a$建立起联系的时候，可能会产生冲突，故在添加$P$的时候，会利用前文提到的Semisort算法对要添加点排个序，按照顺序添加。
    
    总的来说，Prefix Doubling实现了：
    
    - **并行性**：大多数批次足够大，可以利用大量线程进行并行处理。
    - **进度**：在每个批次内部没有争用或竞争，确保顺利进行。
    - **准确性**：每个点插入时看到的是一个相对准确的索引快照。
- 介绍了ANNS的新技术：批次插入和剪枝算法：
    
    ![Untitled](https://raw.githubusercontent.com/xwt1/xwt1.github.io/main/_misc/picture/2024-07-22-ParlayANN/picture1.png)
    
    - 批次插入算法(BatchInsert)，共有两步：
        1. 为新插入点找寻邻居并连边（算法中7-9行），这一步，由于是建立从新点到原始已有索引的**快照**中的点的边，所以这个过程是**确定**的，不会因为多线程的缘故导致不同的连边结果。
        2. 为所有原索引中受到影响的点（被指定为新添加点的邻居的点）添加反向边至新添加的点（算法11到14行），**对于不同受影响的点的边构建是并行化的（如算法3的第11行所示，对每一个不同的$b$处理是并行化的），但对于同一个点的边的构建则是顺序进行的**。算法会首先对批次中点集合$B$进行并行半排序（parallel semisort），设$(b,u)$是算法在这部分要处理的边，$b$是索引中已经存在的点，$u$是新添加的点，那么由于进行了半排序，确保所有对同一个现有点$b$的边是**连续**的（半排序将所有相同键值排在一起），并按照**确定**的顺序排列，这样最终得到的索引结果就是**确定**的。这样不仅避免了原始算法中，多个线程对同一个资源（如这段中描述的$b$点）争抢时需要加锁的问题，提高了并行度，同时也保证了算法结果的**确定**性，非常巧妙。
    - 批次构建算法3(BatchBuild)：
        
        一直重复循环，第$i$轮利用批次插入算法(BatchInsert)插入指定个数的点（第三行），一直循环至将所有点都添加进来。
        
- 介绍了优化技术：批次大小裁剪。为了避免在前缀倍增（prefix-doubling）过程中，**最后几轮批次过大导致信息丢失**，文中提出了对批次大小进行截断的优化方法。具体来说，批次大小被设置了一个上限参数𝜃，经验值设定为0.02𝑛（即数据集大小的2%）。这种优化方法不会影响实际操作中的并行性和可扩展性，因为对于大规模数据集而言，2%的输入数据已经足够利用现代多核计算机的所有线程资源。

### 3.2 基于聚类的办法

- 基于聚类的办法的困难与挑战：
    - **树构建的并行性限制**：一些现有系统通过并行构建多个聚类树（每棵树顺序构建）来实现并行性。然而，由于最优的树数量通常在几十棵（例如HCNNG约30棵），这限制了算法在树构建步骤中的并行性，无法扩展到更多的线程。
    - **合并边时的争用和不确定性**：在合并所有局部ANN图的边时，现有并行实现通常会使用每点锁机制，导致争用问题和不确定性。如果使用修剪（pruning），情况会更糟。
        
        这里因为我没有看过HCNNG的原文，这里有点不明白为什么明明只有内部建边，每个聚簇间并行内部构建索引，还必须对于每个点加锁。因为每个聚簇间应该是不影响的。我猜测是因为聚簇间除了聚簇点需要建边，可能还需要在某些局部点间建边保证索引质量。gpt的回答也是这样，等到时候补一下HCNNG的论文。
        
    - **局部ANN图构建的代价**：一些子程序（如局部ANN图构建）可能会生成耗时或占用大量空间的局部结构，这在数据规模或线程数量较大时会成为性能瓶颈。
        
        我认为这类似于SPANN中提到的情况，即如果聚簇中的点分配不均匀，可能会导致部分局部ANN图过于庞大，从而影响性能。
        
- 并行化基于聚类的办法的算法，提出了两种办法：
    - 第一个办法，并行化了每一个聚类树内索引的构建，原先并行化的程度只能是树之间并行，树内做不到并行。使用并行分治（parallel divide-and-conquer）方法处理每棵树的分支，同时使用并行划分原语将点分配到不同的分支。这种方法不仅在所有叶节点之间提供了丰富的并行性，还在树的内部实现了并行化，从而显著提高了整体算法的并行效率。然而，在HCNNG中，作者观察到过多的线程会导致构建时的空间分配问题。
    - 第二个办法致力于避免并行化时，对于每一个点都要加锁的问题，作者与之前第二节（添加反向边的部分）一样收集所有的边，采用semisort的方法，使得所有以某个点为**弧尾**的边，能够按照固定顺序添加至索引里。

## 4. ParlayANN Algorithms

第四大节讨论了ParlayANN中四种基于图的近似最近邻搜索（ANNS）算法的具体实现和优化。这四种算法包括DiskANN、HNSW、HCNNG和PyNNDescent。以下是每种算法的主要内容和优化措施：

- **DiskANN**:
    - **描述**: DiskANN包含一个内存中的增量ANNS图算法和一个用于在SSD上存储图的系统。本文主要关注内存中的增量ANNS图算法。（本文只关注于in-memory的优化）。
    - **优化措施**: 使用前缀倍增（prefix-doubling）技术来提高在多核机器上的可扩展性。
- **HNSW (Hierarchical Navigable Small World)**:
    - **描述**: HNSW算法构建了一个分层结构，其中每一层是一个可导航的小世界图（NSW）。每一层的节点数量从上到下几何级数地增加，最底层包含所有输入点。
    - **优化措施**: 使用批量插入（batch insertion）和前缀倍增来适应多层结构，移除HNSW中的所有锁，以提高并行性能。
- **HCNNG (Hierarchical Clustering-based Nearest Neighbor Graph)**:
    - **描述**: HCNNG使用聚类树的方法，首先随机选择两个点，将输入分为两部分，直到点的数量低于给定的阈值。叶子簇内的局部ANN图使用度限制最小生成树（MST）构建。
    - **优化措施**: 使用边限制MST（edge-restricted MST）来减少内存使用和提高并行性，从而避免由于过多线程并行运行导致的缓存溢出问题。
    - 说实话，针对MST的并行优化应该有不少，[https://dl.acm.org/doi/abs/10.1145/3448016.3457296](https://dl.acm.org/doi/abs/10.1145/3448016.3457296)，比如这一篇，不知道作者有没有和这些办法比较过，不过一般来说限制一下边数量可能确实是最有效的解决办法，就是不知道图构建出来是否真的不会影响搜索性能。
- **PyNNDescent**:
    - **描述**: 结合了基于聚类的方法和迭代改进的方式，初始聚类通过随机超平面分割点集，叶子簇内的局部ANN图连接每个点到其最近的K个邻居。
    - **优化措施**: 限制每个顶点的度为2000，分批计算两跳邻居集合以减少临时内存使用。

此外，本文还对搜索和布局进行了优化，例如使用一个优化的近似哈希表来提高访问速度，避免图布局中的间接层次。

总结而言，第四大节详细描述了每种算法的实现细节和特定的优化措施，以提高其在多线程环境中的可扩展性和性能。

## 6. 疑问

![Untitled](https://raw.githubusercontent.com/xwt1/xwt1.github.io/main/_misc/picture/2024-07-22-ParlayANN/picture1.png)

我质疑，**在同样的核数情况下，用他的算法构建出来的图会略微比用原来办法构建出来的图的质量差一点**。因为在使用相同的配置参数情况下（如HNSW的M，ef_construction）,diskann（l 图聚簇分片的数量等），你构建的算法与原先算法不一样，最终得到的图肯定不一样的，所以用最终索引画出来的recall-time图也肯定是不一样的。而他后面自己都说了，自己的构建是sequential的近似，所以可以视为劣化。不过如果能构建地更快，稍微劣化一点感觉也没什么问题？